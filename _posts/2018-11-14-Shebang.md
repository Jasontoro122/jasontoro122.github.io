Today, I attended a lecture by Nick Montfort, a professor at MIT. His topic of choice was [How Poetry and Computing Factor into Our Future.](https://cssh.northeastern.edu/internationalcenter/event/how-poetry-and-computing-factor-into-our-future/). During the lecture, Nick Montfort was able to show us several interesting computational poems, such as, but not limited to, [Autopia](http://nickm.com/autopia/), [A House of Dust](https://nickm.com/memslam/a_house_of_dust.html), [2x6, a journey through language as well as automation](https://nickm.com/2/2x6.html), as well as excerpts from several of his books, such as *The Truelist* and *Hard West Turn*, with Alice Parish’s Articulations added to the mixture.  
Though I believe Montfort spent a lot of time on his own work, he did open my eyes, or “future-make”, an interesting ideal for the future. By his definition, a project is “future-making” instead of simply predicting the future when they allow us to think individually and collaboratively in ways we would have never thought before. Vannevar Bush was the big example of this, as his essay *As We May Think* “future-made” all sorts of things, from hypertext to the basic ideas behind advanced encyclopedias that we all know and love, like Wikipedia.  
The only problem I find with his essay is that, after analysis, I’m not particularly sure what comes next for computational poetry. Will the stories that bots produce, such as this [Harry Potter story allegedly developed by bots](https://www.youtube.com/watch?v=9Je8FITk_kQ), become the next epitome of English literature? Or will these poetry and literature bots both do little more than help us analyze literature? This isn’t exactly as horrifying as *Black Mirror*’s people-bots, but it certainly is something to be concerned about in the future, as long as these bots continue to produce books that do as literature has always done; make us think.
