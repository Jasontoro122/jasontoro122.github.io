This week was essentially spent reading *The Lifecycle of Software Objects*, a story about robots with programmed sentience, and the arguments around whether they have real feelings, should be allowed to make decisions for themselves, and their distance from animals. It’s a story about social normatives and sacrifice, but most importantly, about the future of AI.  
A much more basic question asked by the story is “When do we start harming digital things?”, a topic made even more interesting by the [almost century of AI-controlled video games](http://www.museumofplay.org/about/icheg/video-game-history/timeline). Which is what I’m going to talk about.  
Clearly, these digients are more impressive than any sort of AI we’ve been able to put into video games (although [maybe not ones that we’ve made outside of them](https://www.youtube.com/watch?v=E8Ox6H64yu8)), but the concept of sentient AI being the target of antagonistic proportions has been the case since [*The Terminator*](https://en.wikipedia.org/wiki/Skynet_(Terminator)).  
In the video game *Megaman*, you play as Rock, a sentient android. Your goal in the game is to free the other sentient robots who are under the control of Dr. Wily. How do you free them in this game? By shooting them. A lot.  
![alt text](https://github.com/Jasontoro122/jasontoro122.github.io/blob/master/megaman.png “Mega Man fighting some robots.”)  
These enemies are code, but they are made to die. They are made for our entertainment, and we shoot them down. The code presented by Montfort provides a new perspective; in the future, and as games get [more and more complicated](https://en.wikipedia.org/wiki/Fa%C3%A7ade_(video_game)), perhaps games can be analyzed in a similar way… Though some can argue that we already do...
